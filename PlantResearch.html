<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Deep Learning Image Clustering to Aid Species Delimitation Within the Vitis Arizonica Complex</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#section-TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#section-TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="section-TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Stefano Fochesatto</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="course.html">Course Work</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="talks.html">Speaking</a>
</li>
<li>
  <a href="software.html">Programming</a>
</li>
<li>
  <a href="blog.html">Blog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="./files/Stefano_Resume.pdf">
    <span class="ai ai-cv ai-lg"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/StefanoFochesatto">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/stefano-fochesatto-076447213/">
    <span class="fab fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="section-header">



<h1 class="title toc-ignore">Deep Learning Image Clustering to Aid
Species Delimitation Within the Vitis Arizonica Complex</h1>

</div>


<p><link rel="stylesheet" href="styles.css" type="text/css">
<link rel="stylesheet" href="academicicons/css/academicons.min.css"/></p>
<div id="section-introduction" class="section level2">
<h2>Introduction</h2>
<p>The goal of this research is to use machine learning to capture and
quantify the morphological variation inherent in the ~ 370 herbarium
specimen images from several herbaria with large Vitis arizonica complex
collections (ASU, RSA, and US). Specifically we will be applying a
convolutional variational autoencoder to compress these images into a
latent space where a further cluster analysis might reveal biological
insights that could aid in further species delimitation. Ultimately,
these insights could help in an explicit statistical framework for
morphological variation, aiding in delineating species by integrating
morphological and phylogeny data.</p>
</div>
<div id="section-building-the-segmentation-masks"
class="section level2">
<h2>Building the Segmentation Masks</h2>
<p>Before we are able to start working on training a model to cluster
the images we need to remove any biasing information from the images.
This involves creating something called a segmentation mask, which will
essentially remove any biasing information involved in capturing the
herbarium sheet samples. The way that the mask works is we will create a
black and white image, where there is no presence of the plant sample we
will color the image black and where there is we will color the image
white.</p>
<p>In terms of biasing information think, camera settings, or any
identifying labels. Ideally we want the segmentation mask to still
capture all the information that a paleo-botanist would use when
delineating species. I’m told that most of the time this information if
found almost entirely in the morphology of the leaves.</p>
<p>We will be using a workflow described in the following <a
href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7328659/">article</a>
by Alexander White, Rebecca Dikow, et.al, Their article describes
training a neural network to be able to recreate segmentation masks for
fern shaped herbarium sheets. To accomplish this tasks they had to
develop a workflow for creating several ‘ground truth’ masks. This is
the part of their research that we will be taking advantage of.
Currently this workflow involves a good amount of editing by hand if in
the later stages of our research, we decide that more data is needed we
might spend time training a neural network to create these masks for
us.</p>
<p>Mapping out the workflow for building the segmentation masks,
consider the following,</p>
<p><img src="images/SegmentationWorkflow.png" style="width:100%" align="center"></p>
</div>
<div id="section-reformatting-images" class="section level2">
<h2>Reformatting Images</h2>
<p>Some of the Herbarium Sheets were received and stored in the .tiff
file format. In order to save space and have our data in one file format
we will be converting them to .jpg.</p>
<pre class="python"><code>import os
from PIL import Image

# Assuming the current directory has the images. 
yourpath = os.getcwd()
# Extracting file names in current directory. 
for root, dirs, files in os.walk(yourpath, topdown=False):
  # Looping through filenames
  for name in files:
    print(os.path.join(root, name))
      
    # If file ends in tif, check to see if it&#39;s already converted.
    if os.path.splitext(os.path.join(root, name))[1].lower() == &quot;.tif&quot;:
      if os.path.isfile(os.path.splitext(os.path.join(root, name))[0] + &quot;.jpg&quot;):
        print(&quot;A jpeg file already exists for %s&quot; % name)
          # If a jpeg is *NOT* present, create one from the tiff.
      else:
        outfile = os.path.splitext(os.path.join(root, name))[0] + &quot;.jpg&quot;
        try:
          im = Image.open(os.path.join(root, name))
          print(&quot;Generating jpeg for %s&quot; % name)
          im.thumbnail(im.size)
          im.save(outfile, &quot;JPEG&quot;, quality=100)
        except e:
          print(e)</code></pre>
</div>
<div id="section-pre-processing" class="section level2">
<h2>Pre Processing</h2>
<p>The code for the initial segmentation used in the article by
Alexander White, Rebecca Dikow, et al. can be found <a
href="https://github.com/sidatasciencelab/fern_segmentation/blob/master/segmentation_code.ipynb">here</a>.
This initial code relies on an a python wrapper for OpenCV(Computer
Vision) called cv2. The code simply performs Otsu binarization method to
create an initial mask.</p>
<div id="section-otsu-binarization-method" class="section level3">
<h3>Otsu Binarization Method</h3>
<p>The ostsu binarization method finds a threshold for making the mask,
which minimized the intra-class variance(variance between the two black
and white classes.) Here is an example of how it works. First we take
the grayscale image then create a frequency histogram of it’s pixel
intensity values(1-255). We scan through this frequency histogram,
everything to the left of our scan is put into one class everything to
the right of our scan is put into another class. At each iteration we
compute a cost function which is a weighted sum of the variances in each
class,</p>
<p><span class="math display">\[\sigma^2_w(t) = w_1(t)\sigma^2_1(t) +
w_2(t)\sigma^2_2(t).\]</span> <span class="math display">\[w_1(t) =
\sum_{i = 1}^{t - 1}p(i)\]</span> <span class="math display">\[w_2(t) =
\sum_{i = t}^{255}p(i)\]</span></p>
<p>Since there are only two classes, namely black and white we know that
the threshold which minimizes intra-class variance, must also maximize
inter-class variance. Which is computed with the following,</p>
<p><span class="math display">\[ \sigma^2_b(t) =
w_1(t)w_2(t)\left(\mu_1(t)- \mu_2(t)\right)^2.\]</span></p>
<p>Here is some python code for computing the Otsu Binarization
threshold.</p>
<pre class="python"><code>import cv2 #openCV for image processing
import numpy as np

## Area for Otsu Binarization Demo
orig = cv2.imread(&quot;example.jpg&quot;, cv2.IMREAD_GRAYSCALE)
### Generating the greyscale value histogram
freq = np.zeros(256)
for i in range(len(orig)):
    for j in range(len(orig[0])):
        freq[orig[i,j]] += 1

### Normalizing to get probability dist. 
total = sum(freq)
prob = freq/total

## Applying Otsu binarization algorithm to find the threshold which maximizes inter-class variance, 
inter_variance = np.zeros(255)
for i in range(1,256):
    w_0 = sum(prob[0:i-1]) 
    w_1 = sum(prob[i:255])
    if (w_0 == 0 or w_1 == 0):
        inter_variance[i-1] = 0
    else:
        mu_0 = sum(range(1,256)[1:i-1]*prob[1:i-1])/w_0
        mu_1 = sum(range(1,256)[i:255]*prob[i:255])/w_1
        inter_variance[i-1] = w_0*w_1*(mu_0 - mu_1)**2

## Pulling threshold where inter_variance is maximized
Otsu_Thresh = np.argmax(inter_variance)
print(str(&#39;This is the Otsu threshold computed by the novel implemintation: &#39; + str(Otsu_Thresh)))</code></pre>
</div>
</div>
<div id="section-otsu-binarization-demo" class="section level2">
<h2>Otsu Binarization Demo</h2>
<iframe src="https://stefanofochesatto.shinyapps.io/otsudemo/?showcase=0" width="100%" height="550px" data-external="1">
</iframe>
</div>
<div id="section-pre-processing-1" class="section level2">
<h2>Pre Processing</h2>
<div id="section-generating-inital-mask" class="section level4">
<h4>Generating Inital Mask</h4>
<pre class="python"><code>import cv2 #openCV for image processing
import numpy as np

#### Full Script For Initial segmentation mask 
path = &#39;YOUR_PATH&#39; ##Supply Full Path to images directory

#### Directory Management
os.chdir(path) #Change the working directory to the image directory

Imagelist = [] #Pull the current list of files in image directory
for file in os.listdir(path):
    if file.endswith(&quot;.jpg&quot;): # Herbarium Sheets are in jpg format
        Imagelist.append(file)



## Creating Directory for each mask. 
dir_fore = &#39;Foreground_Masks&#39;
os.mkdir(os.path.join(path, dir_fore))
dir_back = &#39;Background_Masks&#39;
os.mkdir(os.path.join(path, dir_back))


for i in Imagelist:
    os.chdir(path) # We have to set the path everytime since cv2 can&#39;t handle relative paths without it.
    currentImage = cv2.imread(i, cv2.IMREAD_GRAYSCALE) # Reading in the current image
    
    # Applying the threshold
    threshImage = copy.deepcopy(currentImage)
    ret, thresh = cv2.threshold(threshImage,0,255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    
    # Creating the masks
    mask_fore = copy.deepcopy(currentImage)
    mask_fore = np.where((currentImage).astype(np.uint8) &gt; ret, 0, 255)  
    image_fore = Image.fromarray((mask_fore).astype(np.uint8))
    os.chdir(str(path+&#39;/Foreground_Masks&#39;))
    image_fore.save(str(i),&quot;JPEG&quot;) 
    
    
    mask_back = copy.deepcopy(currentImage)
    mask_back = np.where((currentImage).astype(np.uint8) &gt; ret, 255, 0) 
    image_back = Image.fromarray((mask_back).astype(np.uint8))
    os.chdir(str(path+&#39;/Background_Masks&#39;))
    image_back.save(str(i),&quot;JPEG&quot;)     </code></pre>
</div>
<div id="section-photoshop-batch-processing" class="section level3">
<h3>Photoshop Batch Processing</h3>
<p>From here we take the initial mask and use Photoshop to erase the
color bar, placard and bar code information that is left behind. So the
workflow so far results in the following segmentation mask.
<img src="images/PreProcessingWorkflow.png" style="width:100%" align="center"></p>
</div>
<div id="section-processing-for-cluster-algorithm"
class="section level3">
<h3>Processing for Cluster Algorithm</h3>
<p>Given the large file size of the post-Photoshop segmentation mask,
and the fact that they are not instance-segmentation masks it makes more
sense to try and cluster the images on a leaf segmentation mask level.
To do so some more preproccessing is required to prepare the images.
First we resized the large segmentation masks, to about half size. We
tested several resizing methods and found that Bit exact nearest
neighbor interpolation was able to best retain information about edge
morphology, for our dataset.</p>
<p>A custom script was written iterate through the resized segmentation
mask images and crop out instances of high quality leafs to be used for
the image clustering (Code to this script will be added to the
programming tab). Finally the leaf instance segmentation were padded to
retain information about relative size, while normalizing and squaring
up the images for the clustering algorithm.</p>
<p>Here is some example code for resizing the large herbarium specimen,
and adding the padding to square up the leaf instance segmentation
masks.</p>
<div id="section-resizing-code" class="section level4">
<h4>Resizing Code:</h4>
<pre class="python"><code>path = r&#39;ADDPATH TO YOUR FULL SIZED SEGMENTATION MASKS&#39;
os.chdir(path) #Change the working directory to the Segmentation Mask directory
SegmentationMaskList = [] #Pull the current list of files in Segmentation Mask directory
for file in os.listdir(path):
    if file.endswith(&quot;.jpg&quot;) and not file.startswith(&#39;.&#39;): 
        SegmentationMaskList.append(file)

SavePath = os.path.join(path, &#39;ResizedInterNearExact&#39;)
os.mkdir(SavePath)
for i in SegmentationMaskList:
        os.chdir(path) 
        # Read in image with segmentation mask
        img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)
        # Resizing
        scaleFactor = 2000/img.shape[0]
        dim = (int(img.shape[1]*scaleFactor),int(img.shape[0]*scaleFactor))
        resized = cv2.resize(img, dim, interpolation = cv2.INTER_NEAREST_EXACT)
        # Saving
        os.chdir(SavePath) 
        Rename = i[:-4] + &#39;_resized.jpg&#39;
        cv2.imwrite(Rename, resized)</code></pre>
</div>
<div id="section-padding-code" class="section level4">
<h4>Padding Code:</h4>
<pre class="python"><code>path = r&#39;ADDPATH TO YOUR RESIZED SEGMENTATION MASKS&#39;
os.chdir(path) #Change the working directory to the Resized Segmentation Masks Directory
SavePath = os.path.join(path, &#39;PaddedSquare&#39;)
os.mkdir(SavePath)
for i in SegmentationMaskList:
       os.chdir(path) 
       img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)
       old_image_height, old_image_width = img.shape

       result = np.full((896,896), 0, dtype=np.uint8)

       # compute center offset
       x_center = (896 - old_image_width) // 2
       y_center = (896 - old_image_height) // 2

       # copy img image into center of result image
       result[y_center:y_center+old_image_height, 
       x_center:x_center+old_image_width] = img
       os.chdir(SavePath) # We have to set the path every time since cv2 can&#39;t handle relative paths without it.
       Rename = i[:-4] + &#39;_Padded.jpg&#39;
       cv2.imwrite(Rename, result)</code></pre>
<p>Finally our pre processing pipeline should look like this.
<img src="images/PreProcessingPipeline.png" style="width:100%" align="center"></p>
</div>
</div>
</div>
<div id="section-deep-embedded-clustering-algorithm"
class="section level2">
<h2>Deep Embedded Clustering Algorithm</h2>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#section-TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
